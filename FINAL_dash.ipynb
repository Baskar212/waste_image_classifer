{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd6255f-f1b7-4ce6-96e6-9b698af8f54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f0001f2ab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error preprocessing image: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0\n",
      "Error classifying image: 'NoneType' object has no attribute 'to'\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, dash_table\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Ensure the uploads directory exists\n",
    "if not os.path.exists(\"uploads\"):\n",
    "    os.makedirs(\"uploads\")\n",
    "\n",
    "# Load the classification model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"trashbox_model.pth\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        from torchvision import models\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(num_ftrs, 7)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        categories = [\"Cardboard\", \"E-Waste\", \"Glass\", \"Medical\", \"Metal\", \"Paper\", \"Plastic\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        model = None\n",
    "        categories = []\n",
    "else:\n",
    "    model = None\n",
    "    categories = []\n",
    "\n",
    "# Waste Type Mapping\n",
    "waste_type_mapping = {\n",
    "    \"Cardboard\": \"Recyclable\",\n",
    "    \"E-Waste\": \"Hazardous\",\n",
    "    \"Glass\": \"Recyclable\",\n",
    "    \"Medical\": \"Hazardous\",\n",
    "    \"Metal\": \"Recyclable\",\n",
    "    \"Paper\": \"Recyclable\",\n",
    "    \"Plastic\": \"Recyclable\"\n",
    "}\n",
    "\n",
    "# Dash App Initialization\n",
    "app = dash.Dash(__name__)\n",
    "server = app.server\n",
    "\n",
    "# Session Data\n",
    "uploaded_images = []\n",
    "waste_counts = {category: 0 for category in categories}\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return \"data:image/png;base64,\" + base64.b64encode(img_file.read()).decode()\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Smart Waste Management System\", style={'textAlign': 'center', 'color': 'blue'}),\n",
    "    \n",
    "    # Upload Section\n",
    "    dcc.Upload(\n",
    "        id='upload-image',\n",
    "        children=html.Button(\"Upload Images\", style={'backgroundColor': 'green', 'color': 'white'}),\n",
    "        multiple=True,\n",
    "        style={\n",
    "            'width': '100%',\n",
    "            'height': '50px',\n",
    "            'lineHeight': '50px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'marginBottom': '10px'\n",
    "        }\n",
    "    ),\n",
    "    html.Div(id='upload-message', style={'color': 'green', 'textAlign': 'center'}),\n",
    "    \n",
    "    # Image Preview\n",
    "    html.Div(id='image-preview', style={'display': 'flex', 'flexWrap': 'wrap', 'gap': '10px', 'marginTop': '10px'}),\n",
    "    \n",
    "    # Classification Section\n",
    "    html.Button(\"Start Classification\", id='start-classification', n_clicks=0, style={'backgroundColor': 'blue', 'color': 'white', 'marginTop': '10px'}),\n",
    "    html.Button(\"Clear All\", id='clear-all', style={'backgroundColor': 'red', 'color': 'white', 'marginLeft': '10px'}),\n",
    "    \n",
    "    # Waste Composition Analysis\n",
    "    dcc.Graph(id='waste-composition-pie', style={'width': '50%', 'height': '400px', 'marginTop': '20px'}),\n",
    "    \n",
    "    # Waste Distribution Graph\n",
    "    dcc.Graph(id='waste-distribution-graph', style={'width': '100%', 'height': '400px'}),\n",
    "    \n",
    "    # Classification Results Table\n",
    "    dash_table.DataTable(\n",
    "        id='classification-results',\n",
    "        columns=[\n",
    "            {'name': 'Item', 'id': 'Item'},\n",
    "            {'name': 'Filename', 'id': 'Filename'},\n",
    "            {'name': 'Resolution', 'id': 'Resolution'},\n",
    "            {'name': 'Category', 'id': 'Category'},\n",
    "            {'name': 'Confidence (%)', 'id': 'Confidence'},\n",
    "            {'name': 'Waste Type', 'id': 'Waste Type'}  # New column for Waste Type\n",
    "        ],\n",
    "        data=[],\n",
    "        style_table={'width': '100%', 'marginTop': '10px'}\n",
    "    ),\n",
    "    \n",
    "    # Export Section\n",
    "    html.Button(\"Export to Excel\", id='export-excel', style={'backgroundColor': 'orange', 'color': 'white', 'marginTop': '10px'}),\n",
    "    html.Div(id='export-message', style={'color': 'blue', 'textAlign': 'center'})\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "@app.callback(\n",
    "    Output('upload-message', 'children'),\n",
    "    Input('upload-image', 'contents'),\n",
    "    State('upload-image', 'filename')\n",
    ")\n",
    "def upload_images(contents, filenames):\n",
    "    if contents is not None:\n",
    "        if not os.path.exists(\"uploads\"):\n",
    "            os.makedirs(\"uploads\")\n",
    "        for content, filename in zip(contents, filenames):\n",
    "            try:\n",
    "                data = content.split(\",\")[1]\n",
    "                img = Image.open(io.BytesIO(base64.b64decode(data)))\n",
    "                path = os.path.join(\"uploads\", filename)\n",
    "                img.save(path)\n",
    "                if path not in uploaded_images:\n",
    "                    uploaded_images.append(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading image {filename}: {e}\")\n",
    "        return \"Images uploaded successfully!\"\n",
    "    return \"\"\n",
    "\n",
    "@app.callback(\n",
    "    [Output('classification-results', 'data'), Output('waste-distribution-graph', 'figure')],\n",
    "    Input('start-classification', 'n_clicks')\n",
    ")\n",
    "def start_classification(n_clicks):\n",
    "    if n_clicks > 0 and uploaded_images:\n",
    "        global waste_counts\n",
    "        waste_counts = {category: 0 for category in categories}\n",
    "        \n",
    "        table_data = []\n",
    "        processed_images = set()\n",
    "        for i, image_path in enumerate(uploaded_images):\n",
    "            if image_path in processed_images:\n",
    "                continue\n",
    "            processed_images.add(image_path)\n",
    "\n",
    "            # Classify image using model\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                if model:\n",
    "                    category, confidence = classify_image(img)\n",
    "                else:\n",
    "                    category, confidence = \"Unknown\", 0.0\n",
    "\n",
    "                resolution = img.size  # Use actual resolution\n",
    "                if category in waste_counts:\n",
    "                    waste_counts[category] += 1\n",
    "                else:\n",
    "                    category = 'Unknown'\n",
    "\n",
    "                # Add Waste Type based on category\n",
    "                table_data.append({\n",
    "                    'Item': f'Item {i+1}',\n",
    "                    'Filename': os.path.basename(image_path),\n",
    "                    'Resolution': f'{resolution[0]}x{resolution[1]}',\n",
    "                    'Category': category,\n",
    "                    'Confidence': f\"{confidence:.2f}\",\n",
    "                    'Waste Type': waste_type_mapping.get(category, \"Unknown\")  # Add Waste Type\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {e}\")\n",
    "        \n",
    "        fig = px.bar(x=list(waste_counts.keys()), y=list(waste_counts.values()), labels={'x': 'Category', 'y': 'Count'})\n",
    "        return table_data, fig\n",
    "    return [], px.bar()\n",
    "\n",
    "@app.callback(\n",
    "    [Output('classification-results', 'data', allow_duplicate=True), Output('waste-distribution-graph', 'figure', allow_duplicate=True)],\n",
    "    Input('clear-all', 'n_clicks'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def clear_all(n_clicks):\n",
    "    if n_clicks > 0:\n",
    "        uploaded_images.clear()\n",
    "        global waste_counts\n",
    "        waste_counts = {category: 0 for category in categories}\n",
    "        return [], px.bar()\n",
    "    return [], px.bar()\n",
    "\n",
    "@app.callback(\n",
    "    Output('export-message', 'children'),\n",
    "    Input('export-excel', 'n_clicks'),\n",
    "    State('classification-results', 'data')\n",
    ")\n",
    "def export_to_excel(n_clicks, data):\n",
    "    if n_clicks is None:  # Handle case where n_clicks is None\n",
    "        return \"\"\n",
    "    \n",
    "    if n_clicks > 0 and data:\n",
    "        try:\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_excel(\"classification_results.xlsx\", index=False)\n",
    "            return \"Data exported to Excel successfully!\"\n",
    "        except Exception as e:\n",
    "            return f\"Error exporting data: {e}\"\n",
    "    return \"\"\n",
    "\n",
    "# Callback for Waste Composition Analysis\n",
    "@app.callback(\n",
    "    Output('waste-composition-pie', 'figure'),\n",
    "    Input('classification-results', 'data')\n",
    ")\n",
    "def update_waste_composition(data):\n",
    "    if not data:\n",
    "        return px.pie(labels=['No Data'], values=[1], title=\"Waste Composition\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    category_counts = df['Category'].value_counts()\n",
    "    fig = px.pie(\n",
    "        values=category_counts.values,\n",
    "        names=category_counts.index,\n",
    "        title=\"Waste Composition\",\n",
    "        hole=0.3,  # Add a hole in the middle for a donut chart\n",
    "        labels={'names': 'Category', 'values': 'Count'}\n",
    "    )\n",
    "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig.update_layout(showlegend=False)\n",
    "    return fig\n",
    "\n",
    "# Helper Functions\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # Resize to the input size expected by ResNet\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        return transform(image).unsqueeze(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def classify_image(image):\n",
    "    try:\n",
    "        input_tensor = preprocess_image(image).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        confidence = torch.nn.functional.softmax(output, dim=1)[0][predicted].item() * 100\n",
    "        return categories[predicted], confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying image: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "# Run the app in Jupyter Notebook\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ef89b-dfef-4e93-9ea6-e496def5087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
